import os
from datetime import datetime
import polars as pl
from aimo3_eval.config import CFG
from aimo3_eval.data.loader import DataLoader
from aimo3_eval.engine.vllm_server import VLLMServer
from aimo3_eval.engine.solver import AIMO3Solver
from aimo3_eval.metrics.evaluator import evaluate_attempts_parquet
from aimo3_eval.metrics.math_utils import MathGrader


def save_results(run_output_dir: str, all_attempts: list, all_times: list):
    """
    ä¿å­˜ç»“æœåˆ°ä¸¤ä¸ª parquet æ–‡ä»¶ï¼š
    - attempts.parquet: æ¯ä¸ª attempt çš„è¯¦ç»†ä¿¡æ¯
    - times.parquet: æ¯ä¸ªé—®é¢˜çš„æ—¶é—´æ±‡æ€»
    """
    attempts_path = os.path.join(run_output_dir, "attempts.parquet")
    times_path = os.path.join(run_output_dir, "times.parquet")
    
    # ä¿å­˜ attempts
    if all_attempts:
        attempts_df = pl.DataFrame(all_attempts)
        attempts_df.write_parquet(attempts_path)
    
    # ä¿å­˜ times
    if all_times:
        times_df = pl.DataFrame(all_times)
        times_df.write_parquet(times_path)
    
    return attempts_path, times_path


def main():
    cfg = CFG(
        mode='remote',
        remote_api_key='sk-xxxx'
    )
    
    # æ„å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
    start_datetime = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_name = cfg.remote_model_name if cfg.mode == 'remote' else cfg.served_model_name
    # æ¸…ç†æ¨¡å‹åç§°ä¸­çš„ç‰¹æ®Šå­—ç¬¦
    model_name_clean = model_name.replace('/', '_').replace(':', '_')
    run_output_dir = os.path.join(cfg.output_dir, f"{cfg.mode}_{model_name_clean}_{start_datetime}")
    os.makedirs(run_output_dir, exist_ok=True)
    print(f"ğŸ“‚ Output directory: {run_output_dir}")
    
    # åªæœ‰åœ¨ local æ¨¡å¼ä¸‹æ‰å¯åŠ¨æœ¬åœ° vLLM
    server = None
    if cfg.mode == 'local':
        server = VLLMServer(cfg)
        server.start()
    else:
        print("â© Skipping local server start (Remote Mode)")

    # Solver ä¼šæ ¹æ® cfg è‡ªåŠ¨è¿åˆ°æ­£ç¡®çš„åœ°æ–¹
    solver = AIMO3Solver(cfg)
    
    df = DataLoader.load_csv(
        "D:\\work_source\\deep_learning\\kaggle\\AIMO3\\aimo3_eval\\data\\reference.csv",
        id_col="id",
        problem_col="problem",
        ground_truth_col="answer"
    )
    df = DataLoader.load_custom_data(
        problems=["What is 2+2?", "Calculate sum of 1 to 100."],
        ids=["demo_1", "demo_2"],
        ground_truths=["4", "5050"]
    )
    print(f"ğŸ“š Loaded {len(df)} problems.")
    
    # å‡†å¤‡è¾“å‡ºæ–‡ä»¶è·¯å¾„
    attempts_path = os.path.join(run_output_dir, "attempts.parquet")
    times_path = os.path.join(run_output_dir, "times.parquet")
    
    all_attempts = []  # å­˜å‚¨æ‰€æœ‰ attempt æ•°æ®
    all_times = []   # å­˜å‚¨æ‰€æœ‰é—®é¢˜çš„æ±‡æ€»ç»“æœ
    
    try:
        # 4. ä¸»å¾ªç¯ - å®æ—¶å¢é‡å†™å…¥
        print("ğŸš€ Start Inference...")
        for idx, row in enumerate(df.iter_rows(named=True), 1):
            problem_id = row['id']
            problem = row['problem']
            ground_truth = str(row.get('ground_truth', ''))
            
            print(f"[{idx}/{len(df)}] Processing {problem_id}...")
            res = solver.solve(problem, problem_id)
            
            # æå–ç»“æœ
            final_answer = str(res['final_answer']) if res['final_answer'] is not None else ''
            
            # åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
            is_correct = MathGrader.is_equiv(final_answer, ground_truth) if ground_truth else False
            
            # æ‰“å°ç»“æœå’Œæ—¶é—´ä¿¡æ¯
            print(f" -> Answer: {final_answer} | Ground Truth: {ground_truth} | Correct: {is_correct}")
            print(f" -> Time - Min: {res['min_attempt_time']:.2f}s | Avg: {res['avg_attempt_time']:.2f}s | Max: {res['max_attempt_time']:.2f}s")
            
            # å¤„ç†æ¯ä¸ª attemptï¼Œæ·»åŠ åˆ° all_attemptsï¼Œå¹¶è®¡ç®—å„æŒ‡æ ‡
            for attempt in res['attempts']:
                attempt_answer = str(attempt.get('final_answer', ''))
                attempt_is_correct = MathGrader.is_equiv(attempt_answer, ground_truth) if ground_truth else False
                
                attempt_record = {
                    "attempt_id": attempt['attempt_id'],
                    "problem_id": problem_id,
                    "problem": problem,
                    "solution": str(attempt.get('messages', [])),  # å°† messages è½¬ä¸ºå­—ç¬¦ä¸²ä½œä¸º solution
                    "answer": attempt_answer,
                    "ground_truth": ground_truth,
                    "isCorrect": attempt_is_correct,
                    "time": attempt.get('time_taken', 0.0),
                    "python_calls": attempt.get('python_calls', 0),
                    "python_errors": attempt.get('python_errors', 0)
                }
                all_attempts.append(attempt_record)
            
            # æ·»åŠ é—®é¢˜æ±‡æ€»ç»“æœåˆ° all_times
            result_record = {
                "problem_id": problem_id,
                "problem": problem,
                "min_attempt_time": res['min_attempt_time'],
                "max_attempt_time": res['max_attempt_time'],
                "avg_attempt_time": res['avg_attempt_time']
            }
            all_times.append(result_record)
            
            # å®æ—¶ä¿å­˜
            save_results(run_output_dir, all_attempts, all_times)
            print(f" âœ… Saved! ")
            
    finally:
        # 5. æ¸…ç†
        solver.cleanup()
        if server:
            server.stop()
        
    results = evaluate_attempts_parquet(
        attempts_path,
        use_math_equiv=True,
        verbose=True
    )

    print(f"\nâœ… Final results saved to:")
    print(f"   - {attempts_path}")
    print(f"   - {times_path}")

if __name__ == "__main__":
    main()