import polars as pl
from collections import Counter
from typing import Optional
from .extractor import AnswerExtractor
from .math_utils import MathGrader


def evaluate_attempts_parquet(
    parquet_path: str,
    use_math_equiv: bool = True,
    verbose: bool = True
) -> dict:
    """
    ä» attempts.parquet æ–‡ä»¶è®¡ç®— pass@1, pass@k, maj@k æŒ‡æ ‡ã€‚
    
    Args:
        parquet_path: parquet æ–‡ä»¶è·¯å¾„ï¼Œéœ€åŒ…å«ä»¥ä¸‹åˆ—:
            - attempt_id: int (å°è¯•ç¼–å·ï¼Œç”¨äºæ’åºç¡®å®šç¬¬ä¸€æ¬¡å°è¯•)
            - problem_id: str (é¢˜ç›®ID)
            - answer: str (è¯¥æ¬¡å°è¯•çš„ç­”æ¡ˆ)
            - ground_truth: str (æ ‡å‡†ç­”æ¡ˆ)
            - isCorrect: bool (å¯é€‰ï¼Œå¦‚å­˜åœ¨åˆ™ç›´æ¥ä½¿ç”¨)
            - time: float (å¯é€‰ï¼Œç”¨äºæ—¶é—´ç»Ÿè®¡)
        use_math_equiv: æ˜¯å¦ä½¿ç”¨ MathGrader.is_equiv è¿›è¡Œæ•°å­¦ç­‰ä»·åˆ¤æ–­
                       å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        åŒ…å«ä»¥ä¸‹æŒ‡æ ‡çš„å­—å…¸:
        - acc_pass@1: ç¬¬ä¸€æ¬¡å°è¯•çš„å‡†ç¡®ç‡
        - acc_pass@k: kæ¬¡å°è¯•ä¸­è‡³å°‘æœ‰ä¸€æ¬¡æ­£ç¡®çš„æ¯”ä¾‹
        - acc_maj@k: ä¼—æ•°æŠ•ç¥¨çš„å‡†ç¡®ç‡
        - total_problems: æ€»é¢˜ç›®æ•°
        - total_attempts: æ€»å°è¯•æ¬¡æ•°
        - k: æ¯é“é¢˜çš„å°è¯•æ¬¡æ•°
        - per_problem: æ¯é“é¢˜çš„è¯¦ç»†æŒ‡æ ‡ (å¯é€‰)
    """
    # è¯»å– parquet æ–‡ä»¶
    df = pl.read_parquet(parquet_path)
    
    if verbose:
        print(f"ğŸ“Š Loaded {len(df)} attempts from {parquet_path}")
        print(f"   Columns: {df.columns}")
    
    # éªŒè¯å¿…è¦çš„åˆ—
    required_cols = ["attempt_id", "problem_id", "answer", "ground_truth"]
    missing_cols = [c for c in required_cols if c not in df.columns]
    if missing_cols:
        raise ValueError(f"Missing required columns: {missing_cols}")
    
    # æŒ‰ problem_id åˆ†ç»„
    pass_1_list = []
    pass_k_list = []
    maj_k_list = []
    per_problem_results = []
    
    # è·å–æ‰€æœ‰å”¯ä¸€çš„ problem_id
    problem_ids = df["problem_id"].unique().to_list()
    
    for problem_id in problem_ids:
        # è·å–è¯¥é¢˜ç›®çš„æ‰€æœ‰ attempts
        problem_df = df.filter(pl.col("problem_id") == problem_id).sort("attempt_id")
        
        ground_truth = problem_df["ground_truth"][0]
        answers = problem_df["answer"].to_list()
        
        # è¿‡æ»¤æ— æ•ˆç­”æ¡ˆ
        valid_answers = [a for a in answers if a and str(a) != 'None' and str(a) != '']
        
        if not valid_answers:
            pass_1_list.append(0)
            pass_k_list.append(0)
            maj_k_list.append(0)
            per_problem_results.append({
                "problem_id": problem_id,
                "pass@1": False,
                "pass@k": False,
                "maj@k": False,
                "first_answer": None,
                "majority_answer": None
            })
            continue
        
        # åˆ¤æ–­å‡½æ•°
        def is_correct(pred: str, truth: str) -> bool:
            if use_math_equiv:
                return MathGrader.is_equiv(str(pred), str(truth))
            else:
                return str(pred).strip() == str(truth).strip()
        
        # --- pass@1: ç¬¬ä¸€æ¬¡å°è¯•æ˜¯å¦æ­£ç¡® ---
        first_answer = valid_answers[0]
        is_pass_1 = is_correct(first_answer, ground_truth)
        pass_1_list.append(1 if is_pass_1 else 0)
        
        # --- pass@k: ä»»æ„ä¸€æ¬¡æ­£ç¡®å³å¯ ---
        is_pass_k = any(is_correct(a, ground_truth) for a in valid_answers)
        pass_k_list.append(1 if is_pass_k else 0)
        
        # --- maj@k: ä¼—æ•°æŠ•ç¥¨ ---
        counts = Counter(valid_answers)
        majority_answer = counts.most_common(1)[0][0]
        is_maj_k = is_correct(majority_answer, ground_truth)
        maj_k_list.append(1 if is_maj_k else 0)
        
        per_problem_results.append({
            "problem_id": problem_id,
            "pass@1": is_pass_1,
            "pass@k": is_pass_k,
            "maj@k": is_maj_k,
            "first_answer": first_answer,
            "majority_answer": majority_answer,
            "ground_truth": ground_truth,
            "num_attempts": len(valid_answers)
        })
    
    # è®¡ç®—æ±‡æ€»æŒ‡æ ‡
    total_problems = len(problem_ids)
    metrics = {
        "acc_pass@1": sum(pass_1_list) / total_problems if total_problems else 0,
        "acc_pass@k": sum(pass_k_list) / total_problems if total_problems else 0,
        "acc_maj@k": sum(maj_k_list) / total_problems if total_problems else 0,
        "total_problems": total_problems,
        "total_attempts": len(df),
        "k": len(df) // total_problems if total_problems else 0,
        "correct_pass@1": sum(pass_1_list),
        "correct_pass@k": sum(pass_k_list),
        "correct_maj@k": sum(maj_k_list),
    }
    
    # æ·»åŠ æ—¶é—´ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ time åˆ—ï¼‰
    if "time" in df.columns:
        metrics["avg_attempt_time"] = df["time"].mean()
        metrics["min_attempt_time"] = df["time"].min()
        metrics["max_attempt_time"] = df["time"].max()
        metrics["total_time"] = df["time"].sum()
    
    # æ·»åŠ æ¯é“é¢˜çš„è¯¦ç»†ç»“æœ
    metrics["per_problem"] = per_problem_results
    
    if verbose:
        print(f"\nğŸ“ˆ Evaluation Results (k={metrics['k']}):")
        print(f"   pass@1: {metrics['acc_pass@1']:.4f} ({metrics['correct_pass@1']}/{total_problems})")
        print(f"   pass@k: {metrics['acc_pass@k']:.4f} ({metrics['correct_pass@k']}/{total_problems})")
        print(f"   maj@k:  {metrics['acc_maj@k']:.4f} ({metrics['correct_maj@k']}/{total_problems})")
        if "total_time" in metrics:
            print(f"   Total time: {metrics['total_time']:.2f}s")
    
    return metrics


def evaluate_dataframe(df: pl.DataFrame) -> dict:
    """
    è¾“å…¥ DataFrame å¿…é¡»åŒ…å«:
    - 'ground_truth': str/int
    - 'attempts': List[dict] (æ¥è‡ª Solver çš„è¾“å‡º)
      å…¶ä¸­æ¯ä¸ª attempt dict éœ€åŒ…å« 'final_answer' å­—æ®µ
      
    è¿”å›: åŒ…å« pass@k, maj@k ç­‰æŒ‡æ ‡çš„å­—å…¸
    """
    
    # 1. æ•°æ®é¢„å¤„ç†ï¼šç¡®ä¿ ground_truth æ˜¯å­—ç¬¦ä¸²
    df = df.with_columns(pl.col("ground_truth").cast(pl.Utf8))
    
    # 2. å®šä¹‰å¤„ç†å•è¡Œçš„é€»è¾‘ (Python Native)
    # ç”±äº SymPy æ— æ³•å‘é‡åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ map_elements æˆ– iter_rows
    # å¯¹äºæµ‹è¯•é›†è§„æ¨¡ (å‡ ç™¾æ¡)ï¼ŒPython Loop æ€§èƒ½å®Œå…¨è¶³å¤Ÿä¸”æ›´æ˜“è°ƒè¯•
    
    pass_1_list = [] # ç¬¬ä¸€æ¬¡å°è¯•æ˜¯å¦æ­£ç¡®
    pass_k_list = [] # kæ¬¡å°è¯•ä¸­æ˜¯å¦è‡³å°‘æœ‰ä¸€æ¬¡æ­£ç¡®
    maj_k_list = []  # ä¼—æ•°æ˜¯å¦æ­£ç¡®
    
    # éå†æ¯ä¸€é“é¢˜
    rows = df.to_dicts()
    for row in rows:
        truth = row['ground_truth']
        attempts = row['attempts']
        
        if not attempts:
            pass_1_list.append(0)
            pass_k_list.append(0)
            maj_k_list.append(0)
            continue

        # æ”¶é›†è¯¥é¢˜ç›®çš„æ‰€æœ‰é¢„æµ‹ç­”æ¡ˆ (å·²ç”± Solver æå–è¿‡ï¼Œè¿™é‡Œå†åšä¸€æ¬¡æ¸…æ´—ç¡®ä¿ä¸‡æ— ä¸€å¤±)
        # æ³¨æ„ï¼šPhase 1 çš„ Solver è¿”å›çš„ attempt['final_answer'] å·²ç»æ˜¯æå–è¿‡çš„äº†
        # ä½†ä¸ºäº†é²æ£’ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ attempt['messages'] æ‹¿å‡ºæ¥é‡è·‘ extractor (å¯é€‰)
        # è¿™é‡Œå‡è®¾ Solver çš„ output å·²ç»æ˜¯æ¸…æ´—è¿‡çš„å­—ç¬¦ä¸²
        preds = [str(a.get('final_answer', '')) for a in attempts]
        preds = [p for p in preds if p and p != 'None'] # è¿‡æ»¤æ— æ•ˆå€¼

        if not preds:
            pass_1_list.append(0)
            pass_k_list.append(0)
            maj_k_list.append(0)
            continue

        # --- Metric: Pass@1 ---
        # å–ç¬¬ä¸€æ¬¡å°è¯•
        is_pass_1 = MathGrader.is_equiv(preds[0], truth)
        pass_1_list.append(1 if is_pass_1 else 0)

        # --- Metric: Pass@k ---
        # åªè¦æœ‰ä¸€ä¸ªå¯¹
        is_pass_k = any(MathGrader.is_equiv(p, truth) for p in preds)
        pass_k_list.append(1 if is_pass_k else 0)

        # --- Metric: Maj@k ---
        # ä¼—æ•°æŠ•ç¥¨
        if preds:
            from collections import Counter
            # ç»Ÿè®¡æ¯ä¸ªç­”æ¡ˆå‡ºç°çš„æ¬¡æ•°
            counts = Counter(preds)
            # æ‰¾åˆ°ç¥¨æ•°æœ€å¤šçš„ç­”æ¡ˆ (å¯èƒ½æœ‰å¤šä¸ªå¹¶åˆ—ï¼Œå–ç¬¬ä¸€ä¸ª)
            major_pred = counts.most_common(1)[0][0]
            is_maj_k = MathGrader.is_equiv(major_pred, truth)
            maj_k_list.append(1 if is_maj_k else 0)
        else:
            maj_k_list.append(0)

    # 3. æ±‡æ€»è®¡ç®—
    metrics = {
        "acc_pass@1": sum(pass_1_list) / len(pass_1_list) if pass_1_list else 0,
        "acc_pass@k": sum(pass_k_list) / len(pass_k_list) if pass_k_list else 0,
        "acc_maj@k": sum(maj_k_list) / len(maj_k_list) if maj_k_list else 0,
        "total_samples": len(rows)
    }
    
    # 4. æ·»åŠ æ—¶é—´ç›¸å…³ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨è¿™äº›å­—æ®µï¼‰
    if "avg_attempt_time" in df.columns:
        metrics["overall_avg_attempt_time"] = df["avg_attempt_time"].mean()
    
    if "min_attempt_time" in df.columns:
        metrics["overall_min_attempt_time"] = df["min_attempt_time"].mean()
    
    if "max_attempt_time" in df.columns:
        metrics["overall_max_attempt_time"] = df["max_attempt_time"].mean()
    
    # 5. ç»Ÿè®¡å…¨å±€æœ€å¿«å’Œæœ€æ…¢çš„å•æ¬¡ attempt
    if "min_attempt_time" in df.columns:
        metrics["fastest_single_attempt"] = df["min_attempt_time"].min()
    
    if "max_attempt_time" in df.columns:
        metrics["slowest_single_attempt"] = df["max_attempt_time"].max()
    
    return metrics