"""
ç»Ÿä¸€çš„è¯„ä¼°è¿è¡Œå™¨ï¼Œå°è£…æ•´ä¸ªè¯„ä¼°æµç¨‹ã€‚
"""
import os
import json
from datetime import datetime
from typing import Optional, List, Dict, Any, Protocol, runtime_checkable

import polars as pl

from aimo3_eval.config import CFG
from aimo3_eval.metrics.math_utils import MathGrader
from aimo3_eval.metrics.evaluator import evaluate_attempts_parquet


@runtime_checkable
class SolverProtocol(Protocol):
    """Solver åè®®ï¼Œæ‰€æœ‰ Solver å¿…é¡»å®ç°è¿™ä¸ªæ¥å£"""
    def solve(self, problem: str, problem_id: str) -> Dict[str, Any]:
        """
        æ±‚è§£å•ä¸ªé—®é¢˜ã€‚
        
        Returns:
            åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸:
            - final_answer: æœ€ç»ˆç­”æ¡ˆ
            - attempts: æ‰€æœ‰å°è¯•çš„åˆ—è¡¨
            - min_attempt_time, max_attempt_time, avg_attempt_time: æ—¶é—´ç»Ÿè®¡
        """
        ...
    
    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        ...


class ResultRecorder:
    """ç»“æœè®°å½•å™¨ï¼Œè´Ÿè´£ä¿å­˜å’Œç®¡ç†è¯„ä¼°ç»“æœ"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.attempts_path = os.path.join(output_dir, "attempts.parquet")
        self.times_path = os.path.join(output_dir, "times.parquet")
        
        self.all_attempts: List[Dict[str, Any]] = []
        self.all_times: List[Dict[str, Any]] = []
    
    def add_result(
        self,
        problem_id: str,
        problem: str,
        ground_truth: str,
        solve_result: Dict[str, Any]
    ) -> bool:
        """
        æ·»åŠ ä¸€ä¸ªé—®é¢˜çš„æ±‚è§£ç»“æœã€‚
        
        Args:
            problem_id: é—®é¢˜ ID
            problem: é—®é¢˜å†…å®¹
            ground_truth: æ­£ç¡®ç­”æ¡ˆ
            solve_result: Solver è¿”å›çš„ç»“æœ
            
        Returns:
            æœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®
        """
        final_answer = str(solve_result['final_answer']) if solve_result['final_answer'] is not None else ''
        is_correct = MathGrader.is_equiv(final_answer, ground_truth) if ground_truth else False
        
        # å¤„ç†æ¯ä¸ª attempt
        for attempt in solve_result['attempts']:
            attempt_answer = str(attempt.get('final_answer', ''))
            attempt_is_correct = MathGrader.is_equiv(attempt_answer, ground_truth) if ground_truth else False
            
            attempt_record = {
                "attempt_id": attempt['attempt_id'],
                "problem_id": problem_id,
                "problem": problem,
                "solution": str(attempt.get('messages', [])),
                "answer": attempt_answer,
                "ground_truth": ground_truth,
                "isCorrect": attempt_is_correct,
                "time": attempt.get('time_taken', 0.0),
                "python_calls": attempt.get('python_calls', 0),
                "python_errors": attempt.get('python_errors', 0)
            }
            self.all_attempts.append(attempt_record)
        
        # æ·»åŠ æ—¶é—´æ±‡æ€»
        time_record = {
            "problem_id": problem_id,
            "problem": problem,
            "min_attempt_time": solve_result['min_attempt_time'],
            "max_attempt_time": solve_result['max_attempt_time'],
            "avg_attempt_time": solve_result['avg_attempt_time']
        }
        self.all_times.append(time_record)
        
        return is_correct
    
    def save(self) -> tuple[str, str]:
        """ä¿å­˜æ‰€æœ‰ç»“æœåˆ° parquet æ–‡ä»¶"""
        if self.all_attempts:
            attempts_df = pl.DataFrame(self.all_attempts)
            attempts_df.write_parquet(self.attempts_path)
        
        if self.all_times:
            times_df = pl.DataFrame(self.all_times)
            times_df.write_parquet(self.times_path)
        
        return self.attempts_path, self.times_path


class EvalRunner:
    """
    ç»Ÿä¸€çš„è¯„ä¼°è¿è¡Œå™¨ã€‚
    
    Example:
        ```python
        cfg = CFG(mode='remote', remote_api_key='sk-xxx')
        solver = AIMO3Solver(cfg)
        
        runner = EvalRunner(cfg, solver)
        runner.load_data(df)  # æˆ– runner.load_csv(path)
        results = runner.run()
        ```
    """
    
    def __init__(
        self,
        cfg: CFG,
        solver: SolverProtocol,
        server: Optional[Any] = None,
        run_name: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–è¿è¡Œå™¨ã€‚
        
        Args:
            cfg: é…ç½®å¯¹è±¡
            solver: å®ç°äº† SolverProtocol çš„æ±‚è§£å™¨
            server: å¯é€‰çš„æœåŠ¡å™¨å®ä¾‹ï¼ˆå¦‚ VLLMServerï¼‰ï¼Œç”¨äºæœ¬åœ°æ¨¡å¼
            run_name: è¿è¡Œåç§°ï¼Œç”¨äºè¾“å‡ºç›®å½•ã€‚å¦‚æœä¸æä¾›ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        """
        self.cfg = cfg
        self.solver = solver
        self.server = server
        self.df: Optional[pl.DataFrame] = None
        
        # æ„å»ºè¾“å‡ºç›®å½•
        if run_name is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = cfg.remote_model_name if cfg.mode == 'remote' else cfg.served_model_name
            model_name_clean = model_name.replace('/', '_').replace(':', '_')
            run_name = f"{cfg.mode}_{model_name_clean}_{timestamp}"
        
        self.output_dir = os.path.join(cfg.output_dir, run_name)
        os.makedirs(self.output_dir, exist_ok=True)
        
        self.recorder = ResultRecorder(self.output_dir)
    
    def load_data(self, df: pl.DataFrame) -> "EvalRunner":
        """
        åŠ è½½æ•°æ®ã€‚
        
        Args:
            df: åŒ…å« id, problem, ground_truth åˆ—çš„ DataFrame
            
        Returns:
            self (æ”¯æŒé“¾å¼è°ƒç”¨)
        """
        self.df = df
        return self
    
    def load_csv(
        self,
        path: str,
        id_col: str = "id",
        problem_col: str = "problem",
        ground_truth_col: str = "answer"
    ) -> "EvalRunner":
        """
        ä» CSV åŠ è½½æ•°æ®ã€‚
        
        Returns:
            self (æ”¯æŒé“¾å¼è°ƒç”¨)
        """
        from aimo3_eval.data.loader import DataLoader
        self.df = DataLoader.load_csv(path, id_col, problem_col, ground_truth_col)
        return self
    
    def run(
        self,
        save_interval: int = 1,
        evaluate_after: bool = True,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        è¿è¡Œè¯„ä¼°æµç¨‹ã€‚
        
        Args:
            save_interval: æ¯å¤„ç†å¤šå°‘ä¸ªé—®é¢˜ä¿å­˜ä¸€æ¬¡ç»“æœ
            evaluate_after: æ˜¯å¦åœ¨å®Œæˆåè‡ªåŠ¨è¯„ä¼°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸ï¼ˆå¦‚æœ evaluate_after=Trueï¼‰
        """
        if self.df is None:
            raise ValueError("No data loaded. Call load_data() or load_csv() first.")
        
        if verbose:
            print(f"ğŸ“‚ Output directory: {self.output_dir}")
            print(f"ğŸ“š Loaded {len(self.df)} problems.")
            print("ğŸš€ Start Inference...")
        
        try:
            for idx, row in enumerate(self.df.iter_rows(named=True), 1):
                problem_id = row['id']
                problem = row['problem']
                ground_truth = str(row.get('ground_truth', ''))
                
                if verbose:
                    print(f"[{idx}/{len(self.df)}] Processing {problem_id}...")
                
                # æ±‚è§£
                result = self.solver.solve(problem, problem_id)
                
                # è®°å½•ç»“æœ
                is_correct = self.recorder.add_result(
                    problem_id, problem, ground_truth, result
                )
                
                # æ‰“å°ç»“æœ
                if verbose:
                    final_answer = result['final_answer']
                    print(f" -> Answer: {final_answer} | Ground Truth: {ground_truth} | Correct: {is_correct}")
                    print(f" -> Time - Min: {result['min_attempt_time']:.2f}s | "
                          f"Avg: {result['avg_attempt_time']:.2f}s | "
                          f"Max: {result['max_attempt_time']:.2f}s")
                
                # å®šæœŸä¿å­˜
                if idx % save_interval == 0:
                    self.recorder.save()
                    if verbose:
                        print(f" âœ… Saved!")
            
            # æœ€ç»ˆä¿å­˜
            attempts_path, times_path = self.recorder.save()
            
            if verbose:
                print(f"\nâœ… Final results saved to:")
                print(f"   - {attempts_path}")
                print(f"   - {times_path}")
            
            # è¯„ä¼°
            if evaluate_after:
                metrics = evaluate_attempts_parquet(
                    attempts_path,
                    use_math_equiv=True,
                    verbose=verbose
                )
                
                # ä¿å­˜ metrics.jsonï¼ˆä»…åŒ…å«æœ€ç»ˆæŒ‡æ ‡ï¼‰
                metrics_json = {
                    "Pass@1": metrics['acc_pass@1'],
                    "Pass@k": metrics['acc_pass@k'],
                    "Maj@k": metrics['acc_maj@k']
                }
                metrics_path = os.path.join(self.output_dir, "metrics.json")
                with open(metrics_path, 'w', encoding='utf-8') as f:
                    json.dump(metrics_json, f, indent=2, ensure_ascii=False)
                
                if verbose:
                    print(f"   - {metrics_path}")
                
                return metrics
            
            return {"attempts_path": attempts_path, "times_path": times_path}
            
        finally:
            self._cleanup()
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self.solver, 'cleanup'):
            self.solver.cleanup()
        if self.server is not None and hasattr(self.server, 'stop'):
            self.server.stop()
